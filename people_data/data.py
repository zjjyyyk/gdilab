import os
import json
import requests
import pandas as pd
from PIL import Image
from io import BytesIO
import shutil

# === é…ç½®éƒ¨åˆ† ===
excel_path = "people_71.xlsx"

origin_dir = "./images/origin"
people_dir = "./images/people"
os.makedirs(origin_dir, exist_ok=True)
os.makedirs(people_dir, exist_ok=True)

undergrad_json = "undergrads.json"
grad_json = "grads.json"
phd_json = "phds.json"
master_json = "masters.json"

# åšå£«ç”Ÿåå•
phd_names = ["ææ³½å®", "å»–ç¾æ˜Š", "é‚¬å¾å®‡", "å´ä½³æ¯…", "å¶å°ä¼Ÿ", "æ›¾è¶Š", "è’‹ä½³ç¥º", "å´ç¿”",
             "ææ´µæ¥·", "å´”å†¬èˆª", "å†·å°é›¨", "æè¯š", "å‘¨ä¿Šæ°", "æ¨ä¸€æ˜¥", "é‚¢å®"]

# === å‹ç¼©å‡½æ•° ===
def compress_image_to_limit(image_path, output_path, max_size_kb=250, min_quality=30, step=5):
    try:
        with Image.open(image_path) as img:
            img_format = img.format or "JPEG"
            quality = 95

            # é˜¶æ®µ1ï¼šè°ƒæ•´è´¨é‡
            while True:
                buffer = BytesIO()
                img.save(buffer, format=img_format, quality=quality, optimize=True)
                size_kb = len(buffer.getvalue()) / 1024
                if size_kb <= max_size_kb or quality <= min_quality:
                    break
                quality -= step

            # é˜¶æ®µ2ï¼šè‹¥ä»è¶…æ ‡ï¼Œç¼©å°å°ºå¯¸
            if size_kb > max_size_kb:
                width, height = img.size
                while size_kb > max_size_kb and (width > 200 or height > 200):
                    width = int(width * 0.9)
                    height = int(height * 0.9)
                    img_resized = img.resize((width, height), Image.LANCZOS)
                    buffer = BytesIO()
                    img_resized.save(buffer, format=img_format, quality=quality, optimize=True)
                    size_kb = len(buffer.getvalue()) / 1024
                    img = img_resized

            # ä¿å­˜å‹ç¼©åå›¾ç‰‡
            with open(output_path, "wb") as f:
                f.write(buffer.getvalue())
    except Exception as e:
        print(f"âš ï¸ å‹ç¼©å¤±è´¥ {image_path}: {e}")

# === è¯»å– Excel æ•°æ® ===
df = pd.read_excel(excel_path, dtype=str).fillna("")

name_col = "1ã€å§“åï¼š"
email_col = "2ã€ä¸ªäººé‚®ç®±"
research_col = "3ã€åœ¨æ ¡ç”Ÿå¡«ç ”ç©¶æ–¹å‘"
grad_col = "4ã€æ˜¯å¦æ¯•ä¸šï¼Œå¦‚æ¯•ä¸šè¯·å¡«æ¯•ä¸šæ—¶é—´"
photo_col = "6ã€ä¸ªäººç…§ç‰‡ï¼ˆä¸è¶…è¿‡ 300*300,100kb, jpgæ ¼å¼ï¼‰ï¼š"

undergrads, grads, phds, masters = [], [], [], []

# === éå†è¡¨æ ¼ ===
for _, row in df.iterrows():
    name = row[name_col].strip()
    email = row[email_col].strip()
    research = row[research_col].strip()
    grad_status = row[grad_col].strip()
    photo_url = row[photo_col].strip()

    origin_filename = f"{name}.jpg"
    origin_path = os.path.join(origin_dir, origin_filename)
    final_filename = f"{name}.jpg"
    final_path = os.path.join(people_dir, final_filename)
    web_path = f"/images/people/{final_filename}"

    # === ä¸‹è½½ç…§ç‰‡åˆ° origin ç›®å½• ===
    if photo_url:
        try:
            r = requests.get(photo_url, timeout=10)
            if r.status_code == 200:
                with open(origin_path, "wb") as f:
                    f.write(r.content)
                size_kb = os.path.getsize(origin_path) / 1024
                if size_kb > 250:
                    om_name = f"OM{name}.jpg"
                    om_path = os.path.join(origin_dir, om_name)
                    os.rename(origin_path, om_path)
                    origin_path = om_path
            else:
                print(f"âŒ ä¸‹è½½å¤±è´¥: {name} ({r.status_code})")
        except Exception as e:
            print(f"âš ï¸ ä¸‹è½½å‡ºé”™ {name}: {e}")

    # === JSON è®°å½• ===
    record = {
        "name": name,
        "photo": web_path,
        "research": research,
        "email": email
    }

    # === åˆ†ç±» ===
    if grad_status in ["å¦", "æœªæ¯•ä¸š", "è¿˜æœªæ¯•ä¸š", "no", "æœªå®Œæˆ"]:
        undergrads.append(record)
        if name in phd_names:
            phds.append(record)
        else:
            masters.append(record)
    else:
        grads.append(record)

# === å†™å…¥ JSON ===
def save_json(filename, data):
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

save_json(undergrad_json, undergrads)
save_json(grad_json, grads)
save_json(phd_json, phds)
save_json(master_json, masters)

print("âœ… JSON æ–‡ä»¶å·²ç”Ÿæˆã€‚")

# === ç¬¬äºŒé˜¶æ®µï¼šå‹ç¼©æ‰€æœ‰ origin å›¾ç‰‡å¹¶å¤åˆ¶åˆ° people ç›®å½• ===
for filename in os.listdir(origin_dir):
    src_path = os.path.join(origin_dir, filename)
    if filename.lower().endswith((".jpg", ".jpeg", ".png")):
        # åˆ é™¤ OM å‰ç¼€åç”Ÿæˆç›®æ ‡å
        clean_name = filename.replace("OM", "", 1) if filename.startswith("OM") else filename
        dst_path = os.path.join(people_dir, clean_name)
        try:
            compress_image_to_limit(src_path, dst_path, max_size_kb=250)
        except Exception as e:
            print(f"âš ï¸ å›¾ç‰‡å¤„ç†å¤±è´¥ {filename}: {e}")

print("ğŸ¯ æ‰€æœ‰å›¾ç‰‡å·²å¤åˆ¶å¹¶å‹ç¼©åˆ° images/people/")
print("âœ… ä»»åŠ¡å…¨éƒ¨å®Œæˆï¼")
